# -*- coding: utf-8 -*-
"""Submission2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HYvGZq2Qw3cn5-RCtlWONSiaoowocBd1

## Model Machine Learning dengan Data Time Series

---

Nama : Ridopandi Sinaga

---

Pandas untuk analisa data, dan drive menghubungkan collab ke gdrive
"""

import pandas as pd
from google.colab import drive
drive.mount('/content/gdrive')

"""Membaca dataset dan juga menampilkannya"""

df = pd.read_csv('/content/gdrive/MyDrive/Dicoding/AEP_hourly.csv')
df.info()
df.head(5)

"""Cek keberadaan missong values pada dataset"""

df.isnull().sum()

"""Menormalisasi dataset"""

import sklearn.preprocessing

def normalize_data(df):
    scaler = sklearn.preprocessing.MinMaxScaler()
    df['AEP_MW']=scaler.fit_transform(df['AEP_MW'].values.reshape(-1,1))
    return df

df_norm = normalize_data(df)
df_norm.shape

"""Mengubah nilai-nilai pada dataframe ke dalam tipe data numpy array serta menampilkan plotting grafik terhadap dataset"""

import matplotlib.pyplot as plt

time = df['Datetime'].values
aep = df['AEP_MW'].values

plt.figure(figsize=(12, 5))
plt.plot(time, aep)
plt.title('Hourly Energy Consumption', fontsize=20)
plt.xlabel('Time', fontsize=12)
plt.ylabel('AEP_MW', fontsize=12)
plt.show()

"""Tampilkan bentuk data dan tipe data"""

df_norm.shape
df.dtypes

"""Membagi dataset menjadi train set dan validation set"""

from sklearn.model_selection import train_test_split

xTrain, xTest, yTrain, yTest = train_test_split(aep, time,train_size=0.8, test_size=0.2, shuffle=False)

print('Total Data Train : ',len(xTrain))
print('Total Data Validation : ',len(xTest))

"""Fungsi untuk menerima sebuah series/atribut  yang telah di konversi menjadi tipe numpy, lalu mengembalikan label dan atribut dari dataset dalam bentuk batch."""

import tensorflow as tf

def windowed_dataset(series, window_size, batch_size, shuffle_buffer):
  series = tf.expand_dims(series, axis=-1)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size + 1, shift=1, drop_remainder=True)
  ds = ds.flat_map(lambda w: w.batch(window_size + 1))
  ds = ds.shuffle(shuffle_buffer)
  ds = ds.map(lambda w: (w[:-1], w[-1:]))
  return ds.batch(batch_size).prefetch(1)

"""Arsitektur model"""

import sklearn.preprocessing
import tensorflow as tf
from keras.models import Sequential
from keras.layers import LSTM, Dense, Bidirectional, Dropout
from sklearn.metrics import r2_score

train_set = windowed_dataset(xTrain, window_size=60, batch_size=200, shuffle_buffer=1000)
test_set  = windowed_dataset(xTest, window_size=60, batch_size=200, shuffle_buffer=1000)

model = tf.keras.models.Sequential([
  Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),
  Bidirectional(tf.keras.layers.LSTM(60, dropout=0.2)),
  Dense(16, activation="relu"),
  Dense(8, activation="relu"),
  Dense(4, activation="relu"),
  Dropout(0.2),
  Dense(1),
])

optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3, momentum=0.9)

model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=optimizer,
    metrics=["mae"]
    )

"""Pengecekan nilai MAE dari model < 10% skala data"""

minMae = (aep.max() - aep.min()) * 10/100
print(minMae)

"""Fungsi callback untuk hentikan training"""

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mae') < minMae and logs.get('val_mae') < minMae):
      print("\MAE dari model < 10% skala data")
      self.model.stop_training = True

stopTraining = myCallback()

"""Training model"""

epoch = 70

history = model.fit(
    train_set,
    epochs= epoch,
    steps_per_epoch = 10,
    validation_data=test_set,
    verbose         = 2,
    callbacks=[stopTraining])

"""Diagram history model mae dan loss"""

import matplotlib.pyplot as plt

# plot of mae
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))

# Plot MAE
axs[0].plot(history.history['mae'])
axs[0].plot(history.history['val_mae'])
axs[0].set_title('MAE')
axs[0].set_ylabel('mae')
axs[0].set_xlabel('epoch')
axs[0].legend(['train', 'test'], loc='lower right')

# Plot Loss
axs[1].plot(history.history['loss'])
axs[1].plot(history.history['val_loss'])
axs[1].set_title('Model Loss')
axs[1].set_ylabel('loss')
axs[1].set_xlabel('epoch')
axs[1].legend(['train', 'test'], loc='upper right')

plt.tight_layout()
plt.show()